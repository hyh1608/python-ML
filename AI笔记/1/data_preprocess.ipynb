{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本：每行表示一个样本  \n",
    "特征：每列表示一个特征  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、均值移除\n",
    "把每个特征的平均值移除，保证处理后的特征均值为零，标准差为1，关注不同样本同一个特征的偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "def std_scale(raw_samples):\n",
    "    std_samples = raw_samples.copy()\n",
    "    cols = std_samples.shape[1]\n",
    "    for col in range(cols):\n",
    "        col_samples = std_samples[:,col]\n",
    "        col_mean = col_samples.mean()\n",
    "        col_std = col_samples.std()\n",
    "        col_samples -= col_mean\n",
    "        col_samples /= col_std\n",
    "    print(std_samples)\n",
    "    return std_samples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.33333333  1.93333333 -0.06666667 -2.53333333]\n",
      "[ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    raw_samples = np.array([\n",
    "        [3,-1.5,2,-5.4],\n",
    "        [0,4,-0.3,2.1],\n",
    "        [1,3.3,-1.9,-4.3]\n",
    "    ])\n",
    "    #求每一列的平均值\n",
    "    raw_means = raw_samples.mean(axis=0)\n",
    "    print(raw_means)\n",
    "    # std_samples = std_scale(raw_samples)\n",
    "    # 调用sklearn中的函数\n",
    "    std_samples = sp.scale(raw_samples)\n",
    "    std_means = std_samples.mean(axis=0)\n",
    "    print(std_means)\n",
    "    std_stds = std_samples.std(axis=0)\n",
    "    print(std_stds)\n",
    "    return 0 \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、范围缩放\n",
    "* 把每个特征的最大值和最小值线性缩放到一个给定的范围  \n",
    "原始样本  \n",
    "x1　　　　　　　　y1  \n",
    "x2　　　　　　　　y2  \n",
    "x3－｛ｋ／ｂ｝－＞y3  \n",
    "...　　　　　　　　...  \n",
    "xn　　　　　　　　yn  \n",
    "xmin * k + b = min    \n",
    "xmax * k + b = max  \n",
    "/ xmin 1 \\ * / k \\ = / min \\  \n",
    "\\ xmax 1 /  &nbsp;\\ b /  &nbsp; \\ max /  \n",
    "　　Ａ　　ｘ　　　ｂ  \n",
    "x = np.linalg.lstsq(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -2.77555756e-16  1.00000000e+00 -2.22044605e-16]\n",
      " [ 1.85037171e-17  1.00000000e+00  4.10256410e-01  1.00000000e+00]\n",
      " [ 3.33333333e-01  8.72727273e-01 -2.22044605e-16  1.46666667e-01]]\n",
      "[[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.41025641 1.        ]\n",
      " [0.33333333 0.87272727 0.         0.14666667]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kokenhei/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "def mmx_scale(raw_samples,min,max):\n",
    "    mmx_samples = raw_samples.copy()\n",
    "    cols = mmx_samples.shape[1]\n",
    "    for col in range(cols):\n",
    "        col_samples = mmx_samples[:,col]\n",
    "        col_min = col_samples.min()\n",
    "        col_max = col_samples.max()\n",
    "        ## np.linalg.lstsq求解\n",
    "        k,b = np.linalg.lstsq(\n",
    "            np.array([[col_min,1],[col_max,1]]),\n",
    "            np.array([min,max]))[0]\n",
    "        col_samples *= k\n",
    "        col_samples += b\n",
    "    return mmx_samples\n",
    "\n",
    "def main():\n",
    "    raw_samples = np.array([\n",
    "        [3,-1.5,2,-5.4],\n",
    "        [0,4,-0.3,2.1],\n",
    "        [1,3.3,-1.9,-4.3]\n",
    "    ])\n",
    "    mmx_samples = mmx_scale(raw_samples,0,1)\n",
    "    print(mmx_samples)\n",
    "    # MinMaxScaler范围缩放函数\n",
    "    # 先生成一个scaler\n",
    "    mmx = sp.MinMaxScaler(feature_range=(0,1))\n",
    "    # 通过fit_transform函数进行转变\n",
    "    mmx_samples = mmx.fit_transform(raw_samples)\n",
    "    print(mmx_samples)\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(sp.MinMaxScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、归一化\n",
    "将每个样本的各个特征值按照一定的比例缩放到[0,1]区间，且该特征值的绝对值之和为1\n",
    "* 需要归一化：基于参数的模型或基于距离的模型，都是要进行特征的归一化 \n",
    "* 不需要归一化：基于树的方法是不需要进行特征的归一化，例如随机森林，bagging 和 boosting等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "def normalize(raw_samples):\n",
    "    nor_samples = raw_samples.copy()\n",
    "    rows = nor_samples.shape[0]\n",
    "    for row in range(rows):\n",
    "        # 是将每个样本按比例缩放\n",
    "        row_samples = nor_samples[row]\n",
    "        row_abs = abs(row_samples)\n",
    "        row_abs_sum = row_abs.sum()\n",
    "        row_samples /= row_abs_sum\n",
    "    return nor_samples\n",
    "\n",
    "def main():\n",
    "    raw_samples = np.array([\n",
    "        [3,-1.5,2,-5.4],\n",
    "        [0,4,-0.3,2.1],\n",
    "        [1,3.3,-1.9,-4.3]\n",
    "    ])\n",
    "    nor_samples = normalize(raw_samples)\n",
    "    print(nor_samples)\n",
    "    for row in range(nor_samples.shape[0]):\n",
    "        row_samples = nor_samples[row]\n",
    "        abs_samples = abs(row_samples)\n",
    "        sum_samples = abs_samples.sum()\n",
    "        print(sum_samples)\n",
    "    # l1即L1范数，矢量中各元素绝对值之和。 \n",
    "    # l2即L2范数，矢量元素绝对值的平方和再开方\n",
    "    nor_samples = sp.normalize(raw_samples,norm='l1')\n",
    "    print(nor_samples)\n",
    "    for row in range(nor_samples.shape[0]):\n",
    "        row_samples = nor_samples[row]\n",
    "        abs_samples = abs(row_samples)\n",
    "        sum_samples = abs_samples.sum()\n",
    "        print(sum_samples)\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、二值化\n",
    "根据一个预先设定的阈值，小于等于阈值统一置0，大于阈值统一置1  \n",
    "** 二值化方法不可逆 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  2.  -5.4]\n",
      " [ 0.   4.  -0.3  2.1]\n",
      " [ 1.   3.3 -1.9 -4.3]]\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "def binarize(raw_samples,threshold):\n",
    "    bin_samples = raw_samples.copy()\n",
    "    bin_samples[bin_samples <= threshold] = 0\n",
    "    bin_samples[bin_samples > threshold] = 1\n",
    "    return bin_samples\n",
    "\n",
    "def main():\n",
    "    raw_samples = np.array([\n",
    "        [3,-1.5,2,-5.4],\n",
    "        [0,4,-0.3,2.1],\n",
    "        [1,3.3,-1.9,-4.3]\n",
    "    ])\n",
    "    print(raw_samples)\n",
    "    bin_samples = binarize(raw_samples,1.4)\n",
    "    print(bin_samples)\n",
    "    # 生成一个二值化器\n",
    "    bin = sp.Binarizer(threshold=1.4)\n",
    "    # 用二值化器进行转化\n",
    "    bin_samples = bin.transform(raw_samples)\n",
    "    print(bin_samples)\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、独热编码\n",
    "只能有一个1  \n",
    "０　　　０　　　３  \n",
    "１　　　１　　　０  \n",
    "０　　　２　　　１  \n",
    "１　　　０　　　２  \n",
    " ---    ----  ----- \n",
    "01　　012　　　0123  \n",
    "2　　　3　　　　4  \n",
    "0-10　0-100　　0-1000  \n",
    "1-01　1-010　　1-0100  \n",
    "　　　2-001　　2-0010  \n",
    "　　　　　　　 3-0001  \n",
    "---   ---     ---- \n",
    "编码字典：  \n",
    "101000001  \n",
    "010101000  \n",
    "100010100  \n",
    "011000010    \n",
    "* 独热编码器.fit_transform(原始样本矩阵) –> return：独热编码后的样本矩阵，同时构建编码表字典，   \n",
    "* 独热编码器.transform(原始样本矩阵) –> return：独热编码后的样本矩阵，使用已有的编码表字典.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3]\n",
      " [1 1 0]\n",
      " [0 2 1]\n",
      " [1 0 2]]\n",
      "[[1 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 1 0 1 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 0]\n",
      " [0 1 1 0 0 0 0 1 0]]\n",
      "[[1 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 1 0 1 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 0]\n",
      " [0 1 1 0 0 0 0 1 0]]\n",
      "[[1 0 0 1 0 0 0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kokenhei/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as sp\n",
    "def onehot_encode(raw_samples):\n",
    "    code_tables = []\n",
    "    for colume in raw_samples.T:\n",
    "        code_table = {}\n",
    "        for value in colume:\n",
    "            code_table[value] = None\n",
    "        code_tables.append(code_table)\n",
    "    \n",
    "    for code_table in code_tables:\n",
    "        size = len(code_table)\n",
    "        # enumerate生成索引和键组成元组的列表\n",
    "        for one,key in enumerate(sorted(code_table.keys())):\n",
    "            code_table[key] = np.zeros(shape=size,dtype=int)\n",
    "            code_table[key][one] = 1\n",
    "            # print(code_table)\n",
    "    # print(code_tables)\n",
    "    ohe_samples = []\n",
    "    for raw_sample in raw_samples:\n",
    "        ohe_sample = np.array([],dtype=int)\n",
    "        for colume,feature in enumerate(raw_sample):\n",
    "            ohe_sample = np.hstack((ohe_sample,\n",
    "                                   code_tables[colume][feature]))\n",
    "        ohe_samples.append(ohe_sample)\n",
    "    return np.array(ohe_samples)\n",
    "\n",
    "def main():\n",
    "    raw_samples = np.array([\n",
    "        [0,0,3],\n",
    "        [1,1,0],\n",
    "        [0,2,1],\n",
    "        [1,0,2]\n",
    "    ])\n",
    "    print(raw_samples)\n",
    "    ohe_samples = onehot_encode(raw_samples)\n",
    "    print(ohe_samples)\n",
    "    # 构造一个独热编码器\n",
    "    ohe = sp.OneHotEncoder(sparse=False,dtype=int)\n",
    "    ohe_samples = ohe.fit_transform(raw_samples)\n",
    "    test_sample1 = np.array([[0,1,2]])\n",
    "    test_sample2 = np.array([[0,4,5]])\n",
    "    # 使用已有的编码表字典\n",
    "    ohe_samples1 = ohe.transform(test_sample1)\n",
    "    # 使用已构建过的独热编码字典进行编码,前提是特征中的状态必须是已有编码字典里的状态，如果存在未出现过的状态，则编码会出现错误\n",
    "    # 无法编码4和5\n",
    "    # ohe_samples2 = ohe.transform(test_sample2)\n",
    "    print(ohe_samples)\n",
    "    print(ohe_samples1)\n",
    "    # print(ohe_samples2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0'), (1, '1')]\n"
     ]
    }
   ],
   "source": [
    "code_table={'0':None,'1':None}\n",
    "print(list(enumerate(sorted(code_table.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、标记编码\n",
    "样本的特征值如果已经是数字，则直接使用它们，如果是字符串，则可以通过标记编码得到与之对应的唯一数字，以方便后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['audi' 'ford' 'audi' 'toyota' 'ford' 'bmw' 'toyota' 'ford' 'audi']\n",
      " ['Benze' 'audi' 'audi' 'bmw' 'toyota' 'ZH' 'Benze' 'bmw' 'audi']]\n",
      "[array([0, 2, 0, 3, 2, 1, 3, 2, 0]), array([0, 2, 2, 3, 4, 1, 0, 3, 2])]\n",
      "[array([0, 2, 0, 3, 2, 1, 3, 2, 0]), array([0, 2, 2, 3, 4, 1, 0, 3, 2])]\n",
      "['Benze' 'audi' 'Benze' 'bmw' 'audi' 'ZH' 'bmw' 'audi' 'Benze']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as sp\n",
    "\n",
    "def main():\n",
    "    raw_labels = np.array([\n",
    "        ['audi','ford','audi','toyota','ford','bmw',\n",
    "        'toyota','ford','audi'],\n",
    "        ['Benze','audi','audi','bmw','toyota','ZH','Benze',\n",
    "        'bmw','audi']\n",
    "    ])\n",
    "    print(raw_labels)\n",
    "    # 生成标签编码器\n",
    "    codec = sp.LabelEncoder()\n",
    "    enc_labels = []\n",
    "    codec = sp.LabelEncoder()\n",
    "    for raw_label in raw_labels:\n",
    "        enc_label = codec.fit_transform(raw_label)\n",
    "        enc_labels.append(enc_label)\n",
    "    print(enc_labels)\n",
    "    # enc_labels = codec.fit_transform(raw_labels)\n",
    "    print(enc_labels)\n",
    "    # 用inverse_transform进行解码\n",
    "    dec_labels = codec.inverse_transform(enc_labels[0])\n",
    "    print(dec_labels)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
