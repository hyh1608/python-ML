# python-ML
# 一、什么是模型？
经验数据---> 规律发现 ---> 验证数据 ---> 实验规律 ---> 完善提高  

1. 建立模型：根据已知样本发现数据间的关系
2. 验证模型：用已知样本检测数据关系的正确性
3. 测试模型：根据未知样本测试模型的业务实用性
4. 使用模型：根据城市的模型构建的业务系统

# 二、典型应用
1. 回归预测：根据历史数据的规律，对未来数据进行预测
2. 分类问题：根据数据的相似性，划分类别  
    1.无监督  
    2.有监督：事先已知类别
3. 推荐引擎：根据用户的商务习惯定制化商务服务
4. 自然语言：根据人类的语言了解语义
5. 语言识别和图像识别：根据声音和图像的特征进行类别划分
6. 人脸/指纹识别：利用人脸/指纹本身的特征信息做精细化的类别划分
7. 神经网络：用一种类似神经系统的结构用最小的成本来解决传统的机器学习问题

# 三、数据预处理
样本：每行表示一个样本
特征：每列表示一个特征
1. 均值移除：把每个特征的平均值移除，保证处理后的特征均值为零，标准差为1，关注不同样本同一个特征的偏差
2. 范围缩放：将每个特征的最大值和最小值线性缩放到一个给定的范围
3. 归一化：将每个样本的各个特征值按照一定的比例缩放到[0,1]区间，且保证特征值得和为1
4. 二值化：根据一个预先设定的阈值，小于等于阈值统一置0，大于阈值统一置1
5. 独热编码
6. 标记编码：样本的特征值如果已经是数字，则直接使用它们，如果是字符串，则可以通过标记编码得到与之对应的唯一数字，以方便后续处理

# 四、线性回归
1. 回归是估计输入数据与输出数据之间的关系。线性回归即假定输入数据和输出数据之间符合线性关系：y = kx+b.训练模型的意义就在根据大量的已知样本[x,y]，按照最小二乘法找到适合的线性参数[k,b]
2. 每一种模型一套评估指标，回归模型参照一下指标：
  * 平均绝对值误差(Mean Absolute Error):所有数据点的误差绝对值的平均数
  * 均方误差(Mean Square Error):所有数据点的误差平方值的平均数，不破坏误差数据本身的连续型规则。
  * 中位数绝对值误差(Median Absolute Error):所有数据点的误差绝对值的中位数，有利于排出某些奇异值的(Outlier)的干扰
  * 解释方差得分(Explained Variance Score):反映模型对数据集波动性的解释能力。如果得分为1，则模型十分完美。[0,1]  
  $1-\frac{Var(y-\hat{y})}{var(y)}$
  * R方得分(R2 Score):反映模型对未知数的预测能力。如果得分为1，则模型十分完美，可能为负。[-1,1] 即拟合优度  
  $R^2(y,\hat{y})=1-\frac{\sum_{i=0}^{n-1}\ (y_i-\hat{y})^2}{\sum_{i=0}^{n-1}\ (y_i-\overline{y})^2}$
3. 训练好的模型(内存中的对象)可被导出(dump)到磁盘文件，以及重新载入(load)到内存，以供交换、传输和重复使用   

# 五、岭回归
1. 线性回归的主要问题是对异常值过于敏感。在真实世界的数据收集过程中，经常会遇到错误的度量结果，而线性回归使用普通的最小二乘法，其目标是使每个样本的误差平方最小。这时，由于异常值误差的绝对值通常较大，会引起回归模型质量的下降。为了避免这个问题，可以引入包含正则化系数(alpha)的岭回归模型，通过阈值和权重来有选择的削弱异常样本对回归效果的影响
2. 经典线性模型是假设自变量之间不具有多重共线性，即不具有相关性，且样本量远远大于待估参数的个数
3. 经典线性模型是根据最小二乘法来确定待估参数的，但若自变量之间存在线性关系，回归系数估计的方差就会很大，估计值就会非常不稳定，会导致无法求广义逆

# 六、多项式回归：非线性
x:[x1,x2,x3] -> y   
y = k1x1 + k2x2 + k3x3 + b  
y = k1x1^1 + k2x2^2 + k3x3^3 + b

# 七、决策树回归和自适应增强决策树回归
1. 决策树模型和自适应增强决策树模型的比较
2. 特征的相对重要性  
在一个特定的回归模型中，影响最终输出的诸特性所作出的贡献并不相同，评估其贡献大小有助于排除影响较小的因素，简化后续数据的处理过程
3. 数据的时间周期对重要性的影响


