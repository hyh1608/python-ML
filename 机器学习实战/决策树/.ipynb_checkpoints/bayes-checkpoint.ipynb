{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于概率论的分类方法：朴素贝叶斯\n",
    "1. 优点：在数据较少的情况下仍然有效，可以处理多类别问题\n",
    "2. 缺点：对于输入数据的准备方式较为敏感\n",
    "3. 适用数据类型：标称型数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的一般过程\n",
    "1. 收集数据：可以使用任何方法。本章使用RSS源\n",
    "2. 准备数据：需要数值型或者布尔型数据\n",
    "3. 分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好\n",
    "4. 训练算法：计算不同的独立特征的条件概率\n",
    "5. 测试算法：计算错误率\n",
    "6. 使用算法：一个常见的朴素贝叶斯应用是文档分类，可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Python进行文本分类\n",
    "### 1. 准备数据：从文本中构建词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词表到向量的转换函数\n",
    "def loadDataSet():\n",
    "    postingList = [['my','dog','has','flea','problems','help','please'],\n",
    "                  ['maybe','not','take','him','to','dog','park','stupid'],\n",
    "                  ['my','dalmation','is','so','cute','I','love','him'],\n",
    "                  ['stop','posting','stupid','worthless','garbage'],\n",
    "                  ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "                  ['quit','buying','worthless','dog','food','stupid']]\n",
    "    classVec = [0,1,0,1,0,1]\n",
    "    return postingList,classVec\n",
    "\n",
    "# 创建一个包含在所有文档中出现的不重复词的列表\n",
    "def createVocabList(dataSet):\n",
    "    # 创建一个空集合\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        # 操作符 | 用于求两个集合的并集\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "\n",
    "def setOfWords2Vec(vocabList,inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(\"the word:%s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOPosts,listClasses = loadDataSet()\n",
    "myVocabList = createVocabList(listOPosts)\n",
    "len(myVocabList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cookie："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog',\n",
       " 'flea',\n",
       " 'has',\n",
       " 'help',\n",
       " 'him',\n",
       " 'maybe',\n",
       " 'my',\n",
       " 'not',\n",
       " 'park',\n",
       " 'please',\n",
       " 'problems',\n",
       " 'stupid',\n",
       " 'take',\n",
       " 'to'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | 求并集\n",
    "vocabSet = set(['my','dog','has','flea','problems','help','please'])\n",
    "document = set(['maybe','not','take','him','to','dog','park','stupid'])\n",
    "a = vocabSet | document\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
