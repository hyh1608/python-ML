{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "决策树的生成过程就是满足使用划分准则的特征，不断的将数据集划分为纯度更高、不确定性更小的子集的过程  \n",
    "### 决策树的一般流程\n",
    "(1) 收集数据：可以使用任何方法  \n",
    "(2) 准备数据：树构造算法只使用于标称型数据，因此数值型数据必须离散化  \n",
    "(3) 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期  \n",
    "(4) 训练算法：构造树的数据结构  \n",
    "(5) 测试算法：使用经验树计算错误率  \n",
    "(6) 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算给定数据集的香农熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def calcShannonEnt(dataSet):\n",
    "    # 获取数据集中实例的总数\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1,1,'yes'],\n",
    "              [1,1,'yes'],\n",
    "              [1,0,'no'],\n",
    "              [0,1,'no'],\n",
    "              [0,1,'no']]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    return dataSet,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 熵越高，则混合的数据也越多\n",
    "myDat[0][-1] = 'maybe'\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照给定特征划分数据集\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最好的数据划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature =i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果数据集已经处理了所有属性，但是类标签依然不是唯一的，\n",
    "# 在这种情况下，我们通常会采用多数表决的的方法决定该叶子节点的分类\n",
    "import operator\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    # reverse=True降序排列，itemgetter(1)用于获取对象的第2维的数据\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建树的函数代码\n",
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del labels[bestFeat]\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "myTree = createTree(myDat,labels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用决策树的分类函数\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    # 得到firstStr的索引值，将标签字符串转换为索引\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__=='dict':\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieveTree输出预先存储的树信息，避免了每次测试代码时都要从数据中创建树的麻烦\n",
    "def retrieveTree(i):\n",
    "    listOfTrees = [{'no surfacing':{0:'no',1:{'flippers':{0:'no',1:'yes'}}}},\n",
    "                  {'no surfacing':{0:'no',1:{'flippers':{0:{'head':{0:'no',1:'yes'}},1:'no'}}}}]\n",
    "    return listOfTrees[i]\n",
    "myTree = retrieveTree(0)\n",
    "myTree\n",
    "classify(myTree,labels,[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(myTree,labels,[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featLabels=['no surfacing','flippers']\n",
    "featIndex = featLabels.index('no surfacing')\n",
    "featIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用算法：决策树的存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pickle模块存储决策树\n",
    "def storeTree(inputTree,filename):\n",
    "    import pickle\n",
    "    #pickle存储方式默认是以字节方式\n",
    "    fw = open(filename,'wb')\n",
    "    # pickle.dump(obj, file[, protocol])，序列化对象，并将结果数据流写入到文件对象中。\n",
    "    # 参数protocol是序列化模式，默认值为0，表示以文本的形式序列化。protocol的值还可以是1或2，表示以二进制的形式序列化。\n",
    "    pickle.dump(inputTree,fw)\n",
    "    fw.close()\n",
    "    \n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename,'rb')\n",
    "    # 反序列化对象。将文件中的数据解析为一个Python对象。\n",
    "    return pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeTree(myTree,'classifierStorage.txt')\n",
    "grabTree('classifierStorage.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用决策树预测隐形眼镜类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       " ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = open('lenses.txt')\n",
    "lenses = [inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'atigmatic': {'no': {'age': {'pre': 'soft',\n",
       "      'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}},\n",
       "      'young': 'soft'}},\n",
       "    'yes': {'prescript': {'hyper': {'age': {'pre': 'no lenses',\n",
       "        'presbyopic': 'no lenses',\n",
       "        'young': 'hard'}},\n",
       "      'myope': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lensesLabels = ['age','prescript','atigmatic','tearRate']\n",
    "lensesTree = createTree(lenses,lensesLabels)\n",
    "lensesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
